p9
# self-reported psychological symptoms
p1 <- data_quest_wide %>%
mutate(group = ifelse((subID %in% planners), "planning", "psychoeducation")) %>%
ggplot(aes(x=PHQ9_total, fill=group, group=group)) +
geom_histogram(alpha=.6, position = "identity") +
theme_minimal() + theme(legend.position = "none") +
geom_vline(xintercept = 10, linetype = "dashed") +  # rough cutoff for clinical depression
scale_colour_manual(values=colours3) +
scale_fill_manual(values=colours3) +
xlab("PHQ9 total")
p4 <- data_quest_wide %>%
mutate(group = ifelse((subID %in% planners), "planning", "psychoeducation")) %>%
ggplot(aes(x=miniSPIN_total, fill=group, group=group)) +
geom_histogram(alpha=.6, position = "identity") + #, binwidth=5
theme_minimal() + theme(legend.position = "none") +
geom_vline(xintercept = 6, linetype = "dashed") +  # rough cutoff for moderate apathy
scale_colour_manual(values=colours3) +
scale_fill_manual(values=colours3) +
xlab("miniSPIN total")
p2 <- data_quest_wide %>%
mutate(group = ifelse((subID %in% planners), "planning", "psychoeducation")) %>%
ggplot(aes(x=AMI_behavActiv, fill=group, group=group)) +
geom_histogram(alpha=.6, position = "identity") +
theme_minimal() + theme(legend.position = "none") +
geom_vline(xintercept = 2.34, linetype = "dashed") +  # rough cutoff for moderate apathy
scale_colour_manual(values=colours3) +
scale_fill_manual(values=colours3) +
xlab("AMI: behavioural")
p3 <- data_quest_wide %>%
mutate(group = ifelse((subID %in% planners), "planning", "psychoeducation")) %>%
ggplot(aes(x=DAS_total, fill=group, group=group)) +
geom_histogram(alpha=.6, position = "identity") +
theme_minimal() + theme(legend.position = "none") +
geom_vline(xintercept = 23.8, linetype = "dashed", colour="dark grey") +  # mean score in dpressed
scale_colour_manual(values=colours3) +
scale_fill_manual(values=colours3) +
xlab("DAS total")
((p1 + p2 ) / (p3 + p4))
(p1 + p2 + p3 + p4) | p8
# catch questions
p0 <- data_quest_wide %>%
mutate(group = ifelse((subID %in% planners), "planning", "psychoeducation")) %>%
ggplot(aes(x=catchQsCorrect, fill=group, group=group)) +
geom_bar(aes(y=..prop..), alpha=.6, position = "dodge") +
theme_minimal() + xlab("catch questions correct?")
p0
View(data_quest_wide)
6*4
24/6
9*4
rm(list=ls())
# knitr options
knitr::opts_chunk$set(echo=FALSE, error=TRUE, warning=FALSE, message=FALSE, fig.align='center')
# # install correct versions of required packages using renv lockfile
# install.packages('renv')
# Sys.setenv(RENV_DOWNLOAD_METHOD = "libcurl")
# renv::init()
# renv::restore(lockfile = "./renv.lock")
# load packages
packages <- c("rjson", "dplyr", "tidyverse", "tidyr", "reshape2",
"ggpmisc", "patchwork", "devtools", "wesanderson", "unikn",
"lme4", "lmerTest", "equatiomatic", "emmeans", "rstatix", "jtools")
if (length(setdiff(packages, rownames(installed.packages()))) > 0 ) {
install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, require, character.only=TRUE)
# load rainCloudPlot src code
source_url("https://raw.githubusercontent.com/RainCloudPlots/RainCloudPlots/master/tutorial_R/R_rainclouds.R")
# set wd
# setwd("/Users/anorbury/Desktop/modcomp/reward-effort-planning")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
## set-up where to look for data, and what task version to get
# where firebase raw output files have been downloaded to
data_dir <- "../data"
# what task version to filter for
task_ver <- "rew-eff-planning2"
data_prolific <- read.csv(file="prolific-export-rew-eff-planning2.csv") %>%
dplyr::select(-X)
data_prolific <- read.csv(file="prolific-export-rew-eff-planning2.csv")
View(data_prolific)
# # get list of individual ppt files (main task data files only)
# quest_data_files <- list.files(path = data_dir,
#                          pattern = paste0("^", task_ver, ".*-self-reports.txt$"),
#                          full.names = TRUE)
# quest_data_files <- quest_data_files[!grepl("5eadaf4eb6da4d086ffdb3ba", quest_data_files) &
#                                        !grepl("5c78f007998fb70001efcb33", quest_data_files) &
#                                           !grepl("5c4f30828f1259000172240d", quest_data_files) &
#                                         !grepl("603760204bc45841d4a59778", quest_data_files)]
# #!! this last ppt wants chance to do other questionnaires (except phq9)
#
# # apply preproc functions to get the data in a nice df format
# data_quest_all <- lapply(quest_data_files, read_quest_json)   # returns nested list of processed data
# data_quest_long <- do.call(rbind, data_quest_all)             # binds all list elements into one big df
# data_quest_wide <- pivot_wider(data_quest_long, id_cols = subID, names_from = quest, values_from = answer) %>%
#   select(-P0_Q0, -study_feedback, -P0_Q7) %>%
#   # fix list data identified using sapply(data_quest_wide, class) so can save as csv
#   mutate(across(c(is.list, -contains("demogs"), -contains("acceptability")),
#                 as.numeric),
#          demogs_age = as.numeric(demogs_age),
#          across(c(is.list),
#                 as.character))
# # fix for 2 participants whose neurodiversity info was saved incorrectly
# data_quest_wide$demogs_neurodiv[data_quest_wide$subID=="5ced731aff8ebb00173b0330"] <- "no"
# data_quest_wide$demogs_neurodiv[data_quest_wide$subID=="614884864a3a786b4fd1195b"] <- "no"
# # save a copy
# write.csv(data_quest_wide, file=paste0(task_ver, "-self-report-data.csv"))
data_quest_wide <- read.csv(file=paste0(task_ver, "-self-report-data.csv")) %>%
dplyr::select(-X)
data_prolific <- read.csv(file="prolific-export-rew-eff-planning2.csv") %>%
filter(Participant.id %in% data_quest_wide$subID)
data_prolific <- read.csv(file="prolific-export-rew-eff-planning2.csv") %>%
filter(Participant.id %in% data_quest_wide$subID) %>%
dplyr::select(Ethnicity.simplified)
view(dfSummary(data_prolific))
61/102
40/102
1/102
rm(list=ls())
# knitr options
knitr::opts_chunk$set(echo=FALSE, error=TRUE, warning=FALSE, message=FALSE, fig.align='center')
# # install correct versions of required packages using renv lockfile
# install.packages('renv')
# Sys.setenv(RENV_DOWNLOAD_METHOD = "libcurl")
# renv::init()
# renv::restore(lockfile = "./renv.lock")
# load packages
packages <- c("rjson", "dplyr", "tidyverse", "tidyr", "reshape2",
"ggpmisc", "patchwork", "devtools", "wesanderson", "unikn",
"lme4", "lmerTest", "equatiomatic", "emmeans", "rstatix", "jtools", "ez")
if (length(setdiff(packages, rownames(installed.packages()))) > 0 ) {
install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, require, character.only=TRUE)
# load rainCloudPlot src code
source_url("https://raw.githubusercontent.com/RainCloudPlots/RainCloudPlots/master/tutorial_R/R_rainclouds.R")
# set wd
# setwd("/Users/anorbury/Desktop/modcomp/reward-effort-planning")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
## set-up where to look for data, and what task version to get
# where firebase raw output files have been downloaded to
data_dir <- "../data"
# what task version to filter for
task_ver <- "rew-eff-planning4"
# # get list of individual ppt files (main task data files only)
# quest_data_files <- list.files(path = data_dir,
#                          pattern = paste0("^", task_ver, ".*-self-reports.txt$"),
#                          full.names = TRUE)
#
# # apply preproc functions to get the data in a nice df format
# data_quest_all <- lapply(quest_data_files, read_quest_json)   # returns nested list of processed data
# data_quest_long <- do.call(rbind, data_quest_all)             # binds all list elements into one big df
# data_quest_wide <- pivot_wider(data_quest_long, id_cols = subID, names_from = quest, values_from = answer) %>%
#   select(-P0_Q0, -study_feedback) %>%
#   # fix list data identified using sapply(data_quest_wide, class) so can save as csv
#   mutate(across(c(is.list, -contains("demogs"), -contains("acceptability")),
#                 as.numeric),
#          demogs_age = as.numeric(demogs_age),
#          across(c(is.list),
#                 as.character))
# # save a copy
# write.csv(data_quest_wide, file=paste0(task_ver, "-self-report-data.csv"))
data_quest_wide <- read.csv(file=paste0(task_ver, "-self-report-data.csv")) %>%
dplyr::select(-X)
data_prolific <- read.csv(file="prolific-export-rew-eff-planning4.csv") %>%
filter(Participant.id %in% data_quest_wide$subID) %>%
dplyr::select(Ethnicity.simplified)
view(dfSummary(data_prolific))
rm(list=ls())
# knitr options
knitr::opts_chunk$set(echo=FALSE, error=TRUE, warning=FALSE, message=FALSE, fig.align='center')
# # install correct versions of required packages using renv lockfile
# install.packages('renv')
# Sys.setenv(RENV_DOWNLOAD_METHOD = "libcurl")
# renv::init()
# renv::restore(lockfile = "./renv.lock")
# # install equatiomatic
# remotes::install_github("datalorax/equatiomatic")
# load packages
packages <- c("rjson", "dplyr", "tidyverse", "tidyr", "reshape2",
"ggpmisc", "patchwork", "devtools", "wesanderson", "unikn",
"lme4", "lmerTest", "subscore", "equatiomatic", "emmeans", "rstatix", "jtools")
if (length(setdiff(packages, rownames(installed.packages()))) > 0 ) {
install.packages(setdiff(packages, rownames(installed.packages())), repos = "http://cran.us.r-project.org")
}
lapply(packages, require, character.only=TRUE)
# load rainCloudPlot src code
source_url("https://raw.githubusercontent.com/RainCloudPlots/RainCloudPlots/master/tutorial_R/R_rainclouds.R")
# set wd
# setwd("~/Desktop/modcomp/tasks/causal-attribution/causal-attribution-learning")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# create figures subdir
subdir <- "figures"
if (!file.exists(subdir)){
dir.create(file.path(dirname(rstudioapi::getActiveDocumentContext()$path), subdir))
}
## set-up where to look for data, and what task version to get
# where firebase raw output files have been downloaded to
data_dir <- "../data"
# what task version to filter for
task_ver <- "causal-attr-pe2"
# # apply preproc functions to get the data in a nice df format
# data_quest_all <- lapply(quest_data_files, read_quest_json)   # returns nested list of processed data
# data_quest_long <- do.call(rbind, data_quest_all)             # binds all list elements into one big df
# data_quest_wide <- pivot_wider(data_quest_long, id_cols = subID, names_from = quest,
#                                values_from = answer) %>%
#   dplyr::select(-P0_Q0, -study_feedback) %>%
#   mutate(demogs_age = replace(demogs_age, subID=="5ed7a0239e6b4a23ec6eb236", 21),
#          demogs_gender = replace(demogs_gender, subID=="5ed7a0239e6b4a23ec6eb236", "man")) %>%
#   # fix list data identified using sapply(data_quest_wide, class) so can save as csv
#   mutate(across(c(is.list, -contains("demogs"), -contains("catch_2"),
#                   -contains("study_acceptability")),
#                 as.numeric),
#          demogs_age = as.numeric(demogs_age),
#          across(c(is.list),
#                 as.character))
# #save a copy
# write.csv(data_quest_wide, file=paste0(task_ver, "-self-report-data.csv"))
# load data
data_quest_wide <- read.csv(file=paste0(task_ver, "-self-report-data.csv")) %>%
dplyr::select(-X)
data_prolific <- read.csv(file="prolific-export-causal-attr-pe2.csv") %>%
filter(Participant.id %in% data_quest_wide$subID) %>%
dplyr::select(Ethnicity.simplified)
view(dfSummary(data_prolific))
data_prolific <- read.csv(file="prolific-export-causal-attr-pe2.csv") %>%
filter(Participant.id %in% data_quest_wide$subID) %>%
dplyr::select(Ethnicity.simplified)
view(dfSummary(data_prolific))
data_prolific <- read.csv(file="prolific-export-causal-attr-pe2.csv") %>%
filter(Participant.id %in% data_quest_wide$subID) %>%
dplyr::select(Ethnicity.simplified) %>%
distinct()
view(dfSummary(data_prolific))
data_prolific <- read.csv(file="prolific-export-causal-attr-pe2.csv") %>%
filter(Participant.id %in% data_quest_wide$subID) %>%
distinct() %>%
dplyr::select(Ethnicity.simplified)
view(dfSummary(data_prolific))
data_prolific <- read.csv(file="prolific-export-causal-attr-pe2.csv") %>%
filter(Participant.id %in% data_quest_wide$subID) %>%
#distinct() %>%
dplyr::select(Ethnicity.simplified)
view(dfSummary(data_prolific))
rm(list=ls())
# knitr options
knitr::opts_chunk$set(echo=FALSE, error=TRUE, warning=FALSE, message=FALSE, fig.align='center')
# # install correct versions of required packages using renv lockfile
# install.packages('renv')
# Sys.setenv(RENV_DOWNLOAD_METHOD = "libcurl")
# renv::init()
# renv::restore(lockfile = "./renv.lock")
# # install equatiomatic
# remotes::install_github("datalorax/equatiomatic")
# load packages
packages <- c("rjson", "dplyr", "tidyverse", "tidyr", "reshape2",
"ggpmisc", "patchwork", "devtools", "wesanderson", "unikn",
"lme4", "lmerTest", "subscore", "equatiomatic", "emmeans", "rstatix", "jtools")
if (length(setdiff(packages, rownames(installed.packages()))) > 0 ) {
install.packages(setdiff(packages, rownames(installed.packages())), repos = "http://cran.us.r-project.org")
}
lapply(packages, require, character.only=TRUE)
# load rainCloudPlot src code
source_url("https://raw.githubusercontent.com/RainCloudPlots/RainCloudPlots/master/tutorial_R/R_rainclouds.R")
# set wd
# setwd("~/Desktop/modcomp/tasks/causal-attribution/causal-attribution-learning")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# create figures subdir
subdir <- "figures"
if (!file.exists(subdir)){
dir.create(file.path(dirname(rstudioapi::getActiveDocumentContext()$path), subdir))
}
## set-up where to look for data, and what task version to get
# where firebase raw output files have been downloaded to
data_dir <- "../data"
# what task version to filter for
task_ver <- "causal-attr-pe3"
# # apply preproc functions to get the data in a nice df format
# data_quest_all <- lapply(quest_data_files, read_quest_json)   # returns nested list of processed data
# data_quest_long <- do.call(rbind, data_quest_all)             # binds all list elements into one big df
# data_quest_wide <- pivot_wider(data_quest_long, id_cols = subID, names_from = quest,
#                                values_from = answer) %>%
#   dplyr::select(-P0_Q0, -study_feedback) %>%
#   # fix list data identified using sapply(data_quest_wide, class) so can save as csv
#   mutate(across(c(is.list, -contains("demogs"), -contains("catch_2"),
#                   -contains("study_acceptability")),
#                 as.numeric),
#          demogs_age = as.numeric(demogs_age),
#          across(c(is.list),
#                 as.character))
#
# # save a copy
# write.csv(data_quest_wide, file=paste0(task_ver, "-self-report-data.csv"))
# load data
data_quest_wide <- read.csv(file=paste0(task_ver, "-self-report-data.csv")) %>%
dplyr::select(-X)
data_prolific <- read.csv(file="prolific-export-causal-attr-pe3.csv") %>%
filter(Participant.id %in% data_quest_wide$subID) %>%
#distinct() %>%
dplyr::select(Ethnicity.simplified)
view(dfSummary(data_prolific))
rm(list=ls())
# knitr options
knitr::opts_chunk$set(echo=FALSE, error=TRUE, warning=FALSE, message=FALSE, fig.align='center')
# # install correct versions of required packages using renv lockfile
# install.packages('renv')
# Sys.setenv(RENV_DOWNLOAD_METHOD = "libcurl")
# renv::init()
# renv::restore(lockfile = "./renv.lock")
# # install equatiomatic
# remotes::install_github("datalorax/equatiomatic")
# load packages
packages <- c("rjson", "dplyr", "tidyverse", "tidyr", "reshape2",
"ggpmisc", "patchwork", "devtools", "ggExtra", "unikn", "svglite",
"lme4", "lmerTest", "subscore", "equatiomatic", "emmeans", "rstatix", "jtools")
if (length(setdiff(packages, rownames(installed.packages()))) > 0 ) {
install.packages(setdiff(packages, rownames(installed.packages())), repos = "http://cran.us.r-project.org")
}
lapply(packages, require, character.only=TRUE)
# load rainCloudPlot src code
source_url("https://raw.githubusercontent.com/RainCloudPlots/RainCloudPlots/master/tutorial_R/R_rainclouds.R")
# set wd
# setwd("~/Desktop/modcomp/tasks/causal-attribution/causal-attribution-learning")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
## set-up where to look for data, and what task version to get
# where firebase raw output files have been downloaded to
data_dir <- "../data"
# what task version to filter for
task_ver <- "rew-eff-causal-attr1"
data_quest_wide <- read.csv(file=paste0(task_ver, "-rew-eff-task-self-report-data.csv")) %>%
dplyr::select(-X)
data_prolific <- read.csv(file="prolific-export-rew-eff-causal-attr.csv") %>%
filter(Participant.id %in% data_quest_wide$subID) %>%
#distinct() %>%
dplyr::select(Ethnicity.simplified)
view(dfSummary(data_prolific))
rm(list=ls())
# knitr options
knitr::opts_chunk$set(echo=FALSE, error=TRUE, warning=FALSE, message=FALSE, fig.align='center')
# # install correct versions of required packages using renv lockfile
# install.packages('renv')
# Sys.setenv(RENV_DOWNLOAD_METHOD = "libcurl")
# renv::init()
# renv::restore(lockfile = "./renv.lock")
# # install equatiomatic
# remotes::install_github("datalorax/equatiomatic")
# load packages
packages <- c("rjson", "dplyr", "tidyverse", "tidyr", "reshape2",
"ggpmisc", "patchwork", "devtools", "wesanderson",
"lme4", "lmerTest", "subscore", "equatiomatic", "emmeans", "rstatix", "jtools")
if (length(setdiff(packages, rownames(installed.packages()))) > 0 ) {
install.packages(setdiff(packages, rownames(installed.packages())), repos = "http://cran.us.r-project.org")
}
lapply(packages, require, character.only=TRUE)
# load rainCloudPlot src code
source_url("https://raw.githubusercontent.com/RainCloudPlots/RainCloudPlots/master/tutorial_R/R_rainclouds.R")
# set wd
# setwd("~/Desktop/modcomp/tasks/causal-attribution/causal-attribution-learning")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# create figs dir
subdir <- "figures"
if (!file.exists(subdir)){
dir.create(file.path(dirname(rstudioapi::getActiveDocumentContext()$path), subdir))
}
## set-up where to look for data, and what task version to get
# where firebase raw output files have been downloaded to
data_dir <- "../data"
# what task version to filter for
task_ver <- "rew-eff-causal-attr1"
# # apply preproc functions to get the data in a nice df format
# data_quest_all <- lapply(quest_data_files, read_quest_json)   # returns nested list of processed data
# data_quest_long <- do.call(rbind, data_quest_all)             # binds all list elements into one big df
# data_quest_wide <- pivot_wider(data_quest_long, id_cols = subID, names_from = quest,
#                                values_from = answer) %>%
#   dplyr::select(-P0_Q0, -study_feedback) %>%
#   # fix list data identified using sapply(data_quest_wide, class) so can save as csv
#   mutate(across(c(is.list, -contains("demogs"), -contains("catch_2"), -contains("study_acceptability")),
#                 as.numeric),
#          demogs_age = as.numeric(demogs_age),
#          across(c(is.list),
#                 as.character))
#
# # save a copy
# write.csv(data_quest_wide, file=paste0(task_ver, "-causal-attr-task-self-report-data.csv"))
# load data
data_quest_wide <- read.csv(file=paste0(task_ver, "-causal-attr-task-self-report-data.csv")) %>%
dplyr::select(-X)
data_prolific <- read.csv(file="prolific-export-rew-eff-causal-attr.csv") %>%
filter(Participant.id %in% data_quest_wide$subID) %>%
#distinct() %>%
dplyr::select(Ethnicity.simplified)
view(dfSummary(data_prolific))
7/208
5/197
37 + 37 + 51 + 53 + 41 + 50
269/6
rm(list=ls())
# knitr options
knitr::opts_chunk$set(echo=FALSE, error=TRUE, warning=FALSE, message=FALSE, fig.align='center')
# # install correct versions of required packages using renv lockfile
# install.packages('renv')
# Sys.setenv(RENV_DOWNLOAD_METHOD = "libcurl")
# renv::init()
# renv::restore(lockfile = "./renv.lock")
# load packages
packages <- c("rstan", "dplyr", "tidyr", "bayesplot", "loo", "hBayesDM", "tidybayes", "forcats",
"ggpmisc", "patchwork", "devtools", "reshape2", "ggExtra", "unikn", "svglite",
"lme4", "glmnet", "ggcorrplot")
if (length(setdiff(packages, rownames(installed.packages()))) > 0 ) {
install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, require, character.only=TRUE)
# set wd
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# what task version to filter for
task_ver <- "rew-eff-planning2"
# create figures subdir
subdir <- "figures"
if (!file.exists(subdir)){
dir.create(file.path(dirname(rstudioapi::getActiveDocumentContext()$path), subdir))
}
model <- "rewEff-linear-bernoulli-multisess-intervention-additive"
fit <- readRDS(file = paste0("./stan-fits/", model , "-", task_ver, "-fit.rds"))
params90cis <- summary(fit, pars = c("mu_effSens[1]", "mu_effSens[2]",
"mu_rewSens[1]", "mu_rewSens[2]",
"rewSens_int", "effSens_int"), probs = c(0.05, 0.95))$summary
print(params90cis)
model <- "rewEff-linear-bernoulli-multisess-intervention-additive-joint-clin-eff-baseline2"
fit <- readRDS(file = paste0("./stan-fits/", model, "-", task_ver, "-fit.rds"))
params90cis <- summary(fit, pars = c("rewSens_int", "effSens_int", "beta_base1", #"beta_base2",
"beta_int"),
probs = c(0.05, 0.95))$summary
print(params90cis)
# knitr options
knitr::opts_chunk$set(echo=FALSE, error=TRUE, warning=FALSE, message=FALSE, fig.align='center')
# # install correct versions of required packages using renv lockfile
# install.packages('renv')
# Sys.setenv(RENV_DOWNLOAD_METHOD = "libcurl")
# renv::init()
# renv::restore(lockfile = "./renv.lock")
# load packages
packages <- c("rstan", "dplyr", "tidyr", "bayesplot", "loo", "hBayesDM", "tidybayes", "forcats",
"ggpmisc", "patchwork", "devtools", "reshape2", "ggExtra", "unikn", "svglite",
"lme4", "glmnet", "ggcorrplot")
if (length(setdiff(packages, rownames(installed.packages()))) > 0 ) {
install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, require, character.only=TRUE)
# set wd
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# what task version to filter for
task_ver <- "rew-eff-planning4"
# create figures subdir
subdir <- "figures"
if (!file.exists(subdir)){
dir.create(file.path(dirname(rstudioapi::getActiveDocumentContext()$path), subdir))
}
model <- "rewEff-linear-bernoulli-multisess-intervention-additive"
fit <- readRDS(file = paste0("./stan-fits/", model , "-", task_ver, "-fit.rds"))
params90cis <- summary(fit, pars = c("mu_effSens[1]", "mu_effSens[2]",
"mu_rewSens[1]", "mu_rewSens[2]",
"rewSens_int", "effSens_int"), probs = c(0.05, 0.95))$summary
print(params90cis)
?summary
# load long format data
data_long_all <- read.csv(file=paste0("./", task_ver, "-task-data-long.csv")) %>%
dplyr::select(-X) %>%
arrange(subID, taskNo, trialNo) %>%
mutate(sess = taskNo,
condition = group,
choice01=recode(choice, "route 1"=0, "route 2"=1))
## get number of time points etc
nPpts <- length(unique(data_long_all$subID))
nTimes <- max(data_long_all$sess)
nTrials_all <- data_long_all %>%
group_by(subID, sess) %>%
summarize(nTrials = n())
nTrials_max <- nTrials_all %>%
{max(.$nTrials)}
# get lists of subjects IDs by condition for use with other data
control_subs <- data_long_all %>%
filter(condition=="control") %>%
dplyr::select(subID, ID)
controls <- as.list(unique(control_subs$subID))
control_IDs <- as.list(unique(control_subs$ID))
# get ordered list of intervention conditions
int_conds <- data_long_all %>%
arrange(ID) %>%
group_by(ID) %>%
dplyr::select(ID, condition) %>%
distinct() %>%
mutate(condition01 = ifelse(condition=="planning", 1, 0))
100*88
8800*0.1
rm(list=ls())
# knitr options
knitr::opts_chunk$set(echo=FALSE, error=TRUE, warning=FALSE, message=FALSE, fig.align='center')
# # install correct versions of required packages using renv lockfile
# install.packages('renv')
# Sys.setenv(RENV_DOWNLOAD_METHOD = "libcurl")
# renv::init()
# renv::restore(lockfile = "./renv.lock")
# load packages
packages <- c("rstan", "dplyr", "tidyr", "bayesplot", "loo", "hBayesDM", "tidybayes", "forcats",
"ggpmisc", "patchwork", "devtools", "reshape2", "ggExtra", "unikn", "svglite",
"lme4", "glmnet", "ggcorrplot", "subscore")
if (length(setdiff(packages, rownames(installed.packages()))) > 0 ) {
install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, require, character.only=TRUE)
# set wd
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
