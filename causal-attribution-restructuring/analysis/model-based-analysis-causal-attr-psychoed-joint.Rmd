---
title: "modComp study psychoeducation intervention model-based analysis of choice task"
output:
  html_document:
    html-math-method:
      method: mathjax
  #  pdf_document:
  # extra_dependencies: ["bbm"]
  # fig_caption: yes
---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo=FALSE, error=TRUE, warning=FALSE, message=FALSE, fig.align='center')

# load packages
packages <- c("rstan", "dplyr", "tidyr", "bayesplot", "loo", "hBayesDM", "tidybayes", "forcats",
              "ggpmisc", "patchwork", "devtools", "reshape2", "ggExtra", "unikn", "svglite",
              "lme4", "glmnet", "ggcorrplot", "subscore", "boot")
if (length(setdiff(packages, rownames(installed.packages()))) > 0 ) {
  install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, require, character.only=TRUE)

# set wd
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# what task version to filter for
task_ver <- "causal-attr1-2"      

# # create figures subdir
# subdir <- "figures"
# if (!file.exists(subdir)){
#   dir.create(file.path(dirname(rstudioapi::getActiveDocumentContext()$path), subdir))
# }
```

```{r setup_rstan}
rstan_options(auto_write = TRUE)     # write the models so we don't have to recompile each time
nCores <- parallel::detectCores()    # get number of cores available for parallelisation
```

```{r setup_colour_scales}
# lets set some custom colour scales for our plots using unikn
#seecol(pal_unikn_pair)
palette2 <- usecol(pal_unikn_pair) 
colours3 <- c("psychoeducation" = palette2[2],
              "control" = palette2[3]               # psychoeducation intervention control
              )
# colours by model parameter type
colours2 <- c("group mean" = palette2[14],
              "intervention effect" = palette2[2],  # active intervention of interest here = psychoed
              "amotivation" = palette2[5],
              "negative cognition" = palette2[13]
              )
```

```{r load_data}
# load long format data
data_long_1 <- read.csv(file=paste0("./", "causal-attr1", "-choice-task-data-long-anon.csv")) %>%
  dplyr::select(-X) %>%
  arrange(uid, taskNo, itemNo) %>%
  mutate(sess = taskNo + 1)

# load long format data
data_long_2 <- read.csv(file=paste0("./", "causal-attr2", "-choice-task-data-long-anon.csv")) %>%
  dplyr::select(-X) %>%
  arrange(uid, taskNo, itemNo) %>%
  mutate(sess = taskNo + 1)

# concat
data_long_all <- rbind(data_long_1, data_long_2) %>%
  dplyr::select(-nTrials, -ID) %>%
  mutate(neg_pos = ifelse(valence=="negative", 0, 1))

## get number of time points etc
nPpts <- length(unique(data_long_all$uid))
nTimes <- max(data_long_all$sess)
nTrials_all <- data_long_all %>%
  arrange(uid) %>%
  group_by(uid) %>%
  summarize(nTrials = n()) %>%
  mutate(ID = seq(1, nPpts, 1))          # assign sequential numeric uids for ease / anonymity

data_long_all <- merge(data_long_all, nTrials_all, by="uid")


nTrials_max <- nTrials_all %>%
  {max(.$nTrials)}

# get lists of subjects IDs by condition for use with other data
control_subs <- data_long_all %>%
  filter(condition=="control") %>%
  dplyr::select(uid, ID)
controls <- as.list(unique(control_subs$uid))
control_IDs <- as.list(unique(control_subs$ID))

# get ordered list of intervention conditions
int_conds <- data_long_all %>%
  arrange(ID) %>%
  group_by(ID) %>%
  dplyr::select(ID, condition) %>%
  distinct() %>%
  mutate(condition01 = ifelse(condition=="psychoed", 1, 0))
```

### Via generative model (both sessions data)

```{r stan_int_models_IG}
## specify model, session, data to fit, and params to save
model <- "m_bernoulli_negpos_IGcorr2_multisess_intervention_additive"

## create arrays of choice options and responses for each participant and time point
internalChosen_neg <- internalChosen_pos <- globalChosen_neg <- globalChosen_pos <- array(0, dim = c(nPpts, nTimes, nTrials_max/2))
nT_ppts <- array(nTrials_max, dim = c(nPpts, nTimes))
for (i in 1:nPpts) {
  for (t in 1:nTimes) {
  internalChosen_neg[i,t,] <- with(data_long_all, internalChosen[ID==i & sess==t & neg_pos==0])
  internalChosen_pos[i,t,] <- with(data_long_all, internalChosen[ID==i & sess==t & neg_pos==1])
  globalChosen_neg[i,t,] <- with(data_long_all, globalChosen[ID==i & sess==t & neg_pos==0])
  globalChosen_pos[i,t,] <- with(data_long_all, globalChosen[ID==i & sess==t & neg_pos==1])
  }
}

## create list to pass to stan
data_list = list(
  nTimes = nTimes,
  nPpts = nPpts,
  nTrials_max = nTrials_max/2,         # max number of trials per  session per participant
  nT_ppts = nT_ppts,                   # actual number of trials per session per participant
  condition = int_conds$condition01,   # 0 = control, 1 = psychoed
  internal_neg = internalChosen_neg,
  internal_pos = internalChosen_pos,
  global_neg = globalChosen_neg,
  global_pos = globalChosen_pos
)

## fit model using rstan
fit <- stan(
  file = paste0("./stan-models/", model, ".stan"),
  data = data_list,
  chains = 4,               # run 4 separate chains to assess convergence
  warmup = 1000,            # these are used to tune the sampler and ’burn in’
  iter = 2000,              # number of iterations (#kept = chains*(iter - warmup))
  cores = nCores            # chains to be run in parallel on separate cores (if possible)
)

## save
saveRDS(fit, file = paste0("./stan-fits/", model ,"-", task_ver, "-fit.rds"))

# summary of sampling diagnostics
check_hmc_diagnostics(fit)

# plot pairs of sampling distributions for an example participant
pairs(fit, pars=c("theta_internal_neg[1,1]", "theta_internal_neg[2,1]",
                  "theta_global_neg[1,1]",   "theta_global_neg[2,1]"))
pairs(fit, pars=c("theta_internal_pos[1,1]", "theta_internal_pos[2,1]",
                  "theta_global_pos[1,1]",   "theta_global_pos[2,1]"))

# plot pairs of sampling distributions for the group level means
pairs(fit, pars=c("mu_internal_theta_neg[1]", "mu_internal_theta_neg[2]",
                  "mu_global_theta_neg[1]",   "mu_global_theta_neg[2]"))
pairs(fit, pars=c("mu_internal_theta_pos[1]", "mu_internal_theta_pos[2]",
                  "mu_global_theta_pos[1]",   "mu_global_theta_pos[2]"))

# plot intervention and individual t2 a[irs ]
pairs(fit, pars=c("theta_int_internal_neg", "theta_int_global_neg"))
pairs(fit, pars=c("theta_int_internal_pos", "theta_int_global_pos"))
```
  
```{r int_IG_plot2}
## load model
model <- "m_bernoulli_negpos_IGcorr2_multisess_intervention_additive"
fit <- readRDS(file = paste0("./stan-fits/", model ,"-",  task_ver, "-fit.rds"))

# test-retest posteriors
R_theta_neg <- as.data.frame(summary(fit, pars = c("R_theta_neg"))$summary)
R_theta_pos <- as.data.frame(summary(fit, pars = c("R_theta_pos"))$summary)

# print mean and mean se for each parameter
# across parameters
print(paste0("R for internal-global attributions for negative items at t1 (mean): ", 
             round(R_theta_neg$mean[2],2)), quote=FALSE)
print(paste0("R for internal-global attribtutions for negative items at t1 (mean SE): ",
             round(R_theta_neg$se_mean[2],3)), quote=FALSE)

print(paste0("R for internal-global attributions for positive items at t1 (mean): ", 
             round(R_theta_pos$mean[2],2)), quote=FALSE)
print(paste0("R for internal-global attribtutions for positive items at t1 (mean SE): ",
             round(R_theta_pos$se_mean[2],3)), quote=FALSE)

print(paste0("R for internal-global attributions for negative items at t2 (mean): ", 
             round(R_theta_neg$mean[12],2)), quote=FALSE)
print(paste0("R for internal-global attribtutions for negative items at t2 (mean SE): ",
             round(R_theta_neg$se_mean[12],3)), quote=FALSE)

print(paste0("R for internal-global attributions for positive items at t2 (mean): ", 
             round(R_theta_pos$mean[12],2)), quote=FALSE)
print(paste0("R for internal-global attribtutions for positive items at t2 (mean SE): ",
             round(R_theta_pos$se_mean[12],3)), quote=FALSE)

# across time points
print(paste0("R for internal attributions for negative items t1-t2 (mean): ", 
             round(R_theta_neg$mean[3],2)), quote=FALSE)
print(paste0("R for internal attributions for negative items t1-t2 (mean SE): ",
             round(R_theta_neg$se_mean[3],3)), quote=FALSE)

print(paste0("R for internal attributions for positive items t1-t2 (mean): ", 
             round(R_theta_pos$mean[3],2)), quote=FALSE)
print(paste0("R for internal attributions for positive items t1-t2 (mean SE): ",
             round(R_theta_pos$se_mean[3],3)), quote=FALSE)

print(paste0("R for global attributions for negative items t1-t2 (mean): ", 
             round(R_theta_neg$mean[8],2)), quote=FALSE)
print(paste0("R for global attributions for negative items t1-t2 (mean SE): ",
             round(R_theta_neg$se_mean[8],3)), quote=FALSE)

print(paste0("R for global attributions for positive items t1-t2 (mean): ", 
             round(R_theta_pos$mean[8],2)), quote=FALSE)
print(paste0("R for global attributions for positive items t1-t2 (mean SE): ",
             round(R_theta_pos$se_mean[8],3)), quote=FALSE)

# plot mean param ests session 1 vs 2
posts <- as.data.frame(summary(fit,
                       pars = c("p_internal_pos", "p_internal_neg",
                                "p_global_pos", "p_global_neg"))$summary) %>%
  dplyr::select(mean, sd) %>%
  add_rownames(var = "var") %>%
  separate(var, sep="\\[|\\,|\\]", into=c("parameter", "ID", "session"),
           remove=TRUE, extra="drop") %>%
  separate(parameter, sep=-3, into=c("parameter", "item_valence")) %>%
  mutate(parameter = sub("l_", "l", parameter))

## plot
p1 <- posts %>%
  pivot_wider(id_cols=c("ID", "parameter", "item_valence"),
              names_from = "session", values_from = c("mean", "sd")) %>%
  mutate(condition = ifelse(ID %in% control_IDs, "control", "psychoeducation")) %>%
  ggplot(aes(x=mean_1, y=mean_2, group=condition, colour=condition)) +
  geom_abline(slope = 1, linetype="dashed", colour="grey") +
  geom_smooth(method = "lm", se=FALSE, formula = y ~ x) +
  geom_point() +
  geom_errorbarh(aes(xmin = mean_1-sd_1, xmax = mean_1+sd_1), alpha=.4) +
  geom_errorbar(aes(ymin = mean_2-sd_2, ymax = mean_2+sd_2), alpha=.4) +
  scale_colour_manual(values=colours3) + 
  scale_fill_manual(values=colours3) +
  labs(x = "mean (sd) time 1", y ="mean (sd) time 2") +
  theme_minimal() + facet_grid(cols=vars(item_valence), rows=vars(parameter)) + labs()
print(p1)
# ggsave(filename = paste0("./figures/", task_ver, "-params-by-time.svg"),
#        plot = last_plot(), device = "svg", dpi = 300)


# plot group-level posteriors using tidybayes package (quick and pretty!)
fit_tidy <- fit %>% 
  gather_draws(`mu_internal_theta_neg[1]`, `mu_internal_theta_neg[2]`, 
               `mu_internal_theta_pos[1]`, `mu_internal_theta_pos[2]`,
               `mu_global_theta_neg[1]`,   `mu_global_theta_neg[2]`, 
               `mu_global_theta_pos[1]`,   `mu_global_theta_pos[2]`, 
               theta_int_internal_neg, theta_int_internal_pos,
               theta_int_global_neg,   theta_int_global_pos) %>%
  mutate(var_type = ifelse(grepl("_int_", .variable), "intervention effect", "group mean"),
         var_type = factor(var_type, levels = c("group mean", "intervention effect")),
         .variable = factor(.variable, levels = c(
           "mu_internal_theta_neg[1]", "mu_internal_theta_neg[2]",
           "mu_internal_theta_pos[1]", "mu_internal_theta_pos[2]",
           "mu_global_theta_neg[1]",   "mu_global_theta_neg[2]",
           "mu_global_theta_pos[1]",   "mu_global_theta_pos[2]",
           "theta_int_internal_neg", "theta_int_internal_pos",
           "theta_int_global_neg", "theta_int_global_pos")))

p <- fit_tidy %>%
  ggplot(aes(y = fct_rev(.variable), x = .value, fill = var_type)) +
  stat_gradientinterval(.width = c(.9, .5),  slab_size = 1) +
  scale_fill_manual(values = colours2) +
  geom_vline(xintercept = 0, colour = "grey") + theme_minimal() +
  theme(legend.position = "none") + theme(aspect.ratio=4/3) + labs(x="", y="")
p
# ggsave(filename = paste0("./figures/", task_ver, "-causal-attr-task-means-ints-CIs-gradient.svg"),
#        plot = last_plot(), device = "svg", dpi = 300)

# print numerical values for 90% CIs (quantile-based)
params90cis <- summary(fit, pars = c("theta_int_internal_neg", "theta_int_internal_pos",
                        "theta_int_global_neg", "theta_int_global_pos"), probs = c(0.1, 0.9))$summary
print(params90cis)

## new plotting
## re-transform group means to output probabilities (cf raw theta estimates which control this)
## and convert intervention effects to ~SMDs
# theta_x_int_std =theta_x_int_sd / sqrt(sigma_theta[2])
# first, get posterior (pooled) variance estimates for theta_x at time 2 (internal, global)
params90cis <- summary(fit, pars = c("pars_sigma_neg[3]",
                                     "pars_sigma_neg[4]", 
                                     "pars_sigma_pos[3]",
                                     "pars_sigma_pos[4]"), probs = c(0.1, 0.9))$summary
sigma_theta_int_neg_t2 <- params90cis[1,1]
sigma_theta_glob_neg_t2 <- params90cis[2,1]
sigma_theta_int_pos_t2 <- params90cis[3,1]
sigma_theta_glob_pos_t2 <- params90cis[4,1]

fit_tidy2 <- fit_tidy %>%
  mutate(.value2 = case_when(.variable =="mu_internal_theta_neg[1]" ~ inv.logit(.value),
                             .variable =="mu_internal_theta_neg[2]" ~ inv.logit(.value),
                             .variable =="mu_internal_theta_pos[1]" ~ inv.logit(.value),
                             .variable =="mu_internal_theta_pos[2]" ~ inv.logit(.value),
                             .variable =="mu_global_theta_neg[1]" ~ inv.logit(.value),
                             .variable =="mu_global_theta_neg[2]" ~ inv.logit(.value),
                             .variable =="mu_global_theta_pos[1]" ~ inv.logit(.value),
                             .variable =="mu_global_theta_pos[2]" ~ inv.logit(.value),
                             .variable =="theta_int_internal_neg" ~ .value/sqrt(sigma_theta_int_neg_t2),
                             .variable =="theta_int_internal_pos" ~ .value/sqrt(sigma_theta_int_pos_t2),
                             .variable =="theta_int_global_neg"   ~ .value/sqrt(sigma_theta_glob_neg_t2),
                             .variable =="theta_int_global_pos"   ~ .value/sqrt(sigma_theta_glob_pos_t2),
                             TRUE ~ .value))
p2 <- fit_tidy2 %>%
  ggplot(aes(y = fct_rev(.variable), x = .value2, fill = var_type)) +
  stat_gradientinterval(.width = c(.9, .5),  slab_size = 1) +
  scale_fill_manual(values = colours2) +
  geom_vline(xintercept = 0, colour = "grey") + theme_minimal() +
  theme(legend.position = "none") + theme(aspect.ratio=4/3) + labs(x="", y="")
p2
# ggsave(filename = paste0("./figures/", task_ver, "-means-ints-CIs-gradient-transf-smd.svg"),
#        plot = last_plot(), device = "svg", dpi = 300)
```


```{r sx_corr_merge}
# load sx data for rew-eff participants
data_quest_wide_1 <- read.csv(file=paste0("causal-attr1", "-self-report-data-anon.csv")) %>%
  dplyr::select(-X, -catch_1, -catchQsCorrect)

# load sx data for rew-eff participants
data_quest_wide_2 <- read.csv(file=paste0("causal-attr2", "-self-report-data-anon.csv")) %>%
  dplyr::select(-X)

# concat
data_quest_wide_all <- rbind(data_quest_wide_1, data_quest_wide_2) %>%
  arrange(uid)

# get key linking numeric sequential IDs in model outtput back to original prolific identifiers
ID_trans <- data_long_all %>%
  dplyr::select(uid, ID) %>%
  distinct()

# merge sx into posts data
posts_uids <- merge(posts, ID_trans, by="ID")
posts_sx <- merge(posts_uids, data_quest_wide_all, by = "uid") %>%
  arrange(uid)
```


```{r sx_corr_plot}
# plot relationships between t1 posterior means and sx scores
p2 <- posts_sx %>%
  filter(session==1) %>%
  ggplot(aes(x = PHQ9_total, y = mean)) +
  geom_point() +
  geom_smooth(method = "lm", se=TRUE, alpha=.2, color="black", formula = y ~ x) +
  stat_poly_eq(formula = y~x, label.x = "right", label.y = "top",
               aes(label = paste(stat(rr.label), stat(p.value.label), sep = "~~~")),
               parse = TRUE) +
  theme_minimal() + facet_grid(rows = vars(item_valence), cols = vars(parameter)) 
p2

p3 <- posts_sx %>%
  filter(session==1) %>%
  ggplot(aes(x = miniSPIN_total, y = mean)) +
  geom_point() +
  geom_smooth(method = "lm", se=TRUE, alpha=.2, color="black", formula = y ~ x) +
  stat_poly_eq(formula = y~x, label.x = "right", label.y = "top",
               aes(label = paste(stat(rr.label), stat(p.value.label), sep = "~~~")),
               parse = TRUE) +
  theme_minimal() + facet_grid(rows = vars(item_valence), cols = vars(parameter)) 
p3

p4 <- posts_sx %>%
  filter(session==1) %>%
  ggplot(aes(x = DAS_total, y = mean)) +
  geom_point() +
  geom_smooth(method = "lm", se=TRUE, alpha=.2, color="black", formula = y ~ x) +
  stat_poly_eq(formula = y~x, label.x = "right", label.y = "top",
               aes(label = paste(stat(rr.label), stat(p.value.label), sep = "~~~")),
               parse = TRUE) +
  theme_minimal() + facet_grid(rows = vars(item_valence), cols = vars(parameter)) 
p4
```

```{r hte_internal}
# assessment of tx heterogeneity, as per https://journals.physiology.org/doi/full/10.1152/japplphysiol.00098.2015
# individual responses are summarized by a standard deviation (SD_IR) given by the square root of the difference between the squares of the standard deviations of the change scores in the experimental (SD_Exp) and control (SD_Con) groups: SD_IR = √(SD_Exp^2 − SD_Con^2)
hte <- posts_sx %>%
  filter(parameter=="p_internal" & item_valence=="neg") %>%
  group_by(uid) %>%
  mutate(psychoed = ifelse(uid %in% controls, 0, 1),
         deltaPneg = mean[session==2] - mean[session==1]) %>%
  filter(session==1) %>%
  ungroup() %>%
  mutate(deltaPnegStd = deltaPneg / sd(mean)) %>%
  group_by(psychoed) %>%
  summarise(sd = sd(deltaPnegStd), N=n())

SD_exp <- hte$sd[hte$psychoed==1]
DF_exp <- hte$N[hte$psychoed==1] - 1
SD_con <- hte$sd[hte$psychoed==0]
DF_con <- hte$N[hte$psychoed==0] - 1
SD_IR <- sqrt(SD_exp^2 - SD_con^2)

print(paste0("Point estimate for SD of individual responses in mean internal theta_neg: ",
             round(SD_IR,3)), quotes=FALSE)

# Confidence limits for the standard deviation are obtained by assuming its sampling variance is normally distributed, with standard error given by √[2(SDExp4/DFExp+SDCon4/DFCon)], where DFExp and DFCon are the degrees of freedom of the standard deviations in the two groups (usually their sample sizes minus 1).
SD_IR_se <- sqrt(2 * ( SD_exp^4/DF_exp + SD_con^4/DF_con))

# The upper and lower confidence limits for the true value of the variance of individual responses (SDIR2) are given by its observed value plus or minus this standard error times 1.65, 1.96, or 2.58 for 90, 95, or 99% confidence limits, respectively
print(paste0("95% CI for variance in individual responses in mean internal theta_neg: ",
             round(SD_IR - 1.96*SD_IR_se,3), 
             " - ",
             round(SD_IR + 1.96*SD_IR_se,3)), quotes=FALSE)

# The thresholds for interpreting the standardized mean change (0.2, 0.6, 1.2, 2.0, and 4.0 for small, moderate, large, very large, and extremely large) (6) need to be halved (0.1, 0.3, 0.6, 1.0, and 2.0) for interpreting the magnitude of effects represented by standardized standard deviations (8), including individual responses.


hte <- posts_sx %>%
  filter(parameter=="p_internal" & item_valence=="pos") %>%
  group_by(uid) %>%
  mutate(psychoed = ifelse(uid %in% controls, 0, 1),
         deltaPpos = mean[session==2] - mean[session==1]) %>%
  filter(session==1) %>%
  ungroup() %>%
  mutate(deltaPposStd = deltaPpos / sd(mean)) %>%
  group_by(psychoed) %>%
  summarise(sd = sd(deltaPposStd), N=n())

SD_exp <- hte$sd[hte$psychoed==1]
DF_exp <- hte$N[hte$psychoed==1] - 1
SD_con <- hte$sd[hte$psychoed==0]
DF_con <- hte$N[hte$psychoed==0] - 1
SD_IR <- sqrt(SD_exp^2 - SD_con^2)

print(paste0("Point estimate for SD of individual responses in mean internal theta_pos: ",
             round(SD_IR,3)), quotes=FALSE)

# Confidence limits for the standard deviation are obtained by assuming its sampling variance is normally distributed, with standard error given by √[2(SDExp4/DFExp+SDCon4/DFCon)], where DFExp and DFCon are the degrees of freedom of the standard deviations in the two groups (usually their sample sizes minus 1).
SD_IR_se <- sqrt(2 * ( SD_exp^4/DF_exp + SD_con^4/DF_con))

# The upper and lower confidence limits for the true value of the variance of individual responses (SDIR2) are given by its observed value plus or minus this standard error times 1.65, 1.96, or 2.58 for 90, 95, or 99% confidence limits, respectively
print(paste0("95% CI for variance in individual responses in mean internal theta_pos: ",
             round(SD_IR - 1.96*SD_IR_se,3), 
             " - ",
             round(SD_IR + 1.96*SD_IR_se,3)), quotes=FALSE)

# The thresholds for interpreting the standardized mean change (0.2, 0.6, 1.2, 2.0, and 4.0 for small, moderate, large, very large, and extremely large) (6) need to be halved (0.1, 0.3, 0.6, 1.0, and 2.0) for interpreting the magnitude of effects represented by standardized standard deviations (8), including individual responses.
```

```{r hte_global}
# assessment of tx heterogeneity, as per https://journals.physiology.org/doi/full/10.1152/japplphysiol.00098.2015
# individual responses are summarized by a standard deviation (SD_IR) given by the square root of the difference between the squares of the standard deviations of the change scores in the experimental (SD_Exp) and control (SD_Con) groups: SD_IR = √(SD_Exp^2 − SD_Con^2)
hte <- posts_sx %>%
  filter(parameter=="p_global" & item_valence=="neg") %>%
  group_by(uid) %>%
  mutate(psychoed = ifelse(uid %in% controls, 0, 1),
         deltaPneg = mean[session==2] - mean[session==1]) %>%
  filter(session==1) %>%
  ungroup() %>%
  mutate(deltaPnegStd = deltaPneg / sd(mean)) %>%
  group_by(psychoed) %>%
  summarise(sd = sd(deltaPnegStd), N=n())

SD_exp <- hte$sd[hte$psychoed==1]
DF_exp <- hte$N[hte$psychoed==1] - 1
SD_con <- hte$sd[hte$psychoed==0]
DF_con <- hte$N[hte$psychoed==0] - 1
SD_IR <- sqrt(SD_exp^2 - SD_con^2)

print(paste0("Point estimate for SD of individual responses in mean global theta_neg: ",
             round(SD_IR,3)), quotes=FALSE)

# Confidence limits for the standard deviation are obtained by assuming its sampling variance is normally distributed, with standard error given by √[2(SDExp4/DFExp+SDCon4/DFCon)], where DFExp and DFCon are the degrees of freedom of the standard deviations in the two groups (usually their sample sizes minus 1).
SD_IR_se <- sqrt(2 * ( SD_exp^4/DF_exp + SD_con^4/DF_con))

# The upper and lower confidence limits for the true value of the variance of individual responses (SDIR2) are given by its observed value plus or minus this standard error times 1.65, 1.96, or 2.58 for 90, 95, or 99% confidence limits, respectively
print(paste0("95% CI for variance in individual responses in mean global theta_neg: ",
             round(SD_IR - 1.96*SD_IR_se,3), 
             " - ",
             round(SD_IR + 1.96*SD_IR_se,3)), quotes=FALSE)

# The thresholds for interpreting the standardized mean change (0.2, 0.6, 1.2, 2.0, and 4.0 for small, moderate, large, very large, and extremely large) (6) need to be halved (0.1, 0.3, 0.6, 1.0, and 2.0) for interpreting the magnitude of effects represented by standardized standard deviations (8), including individual responses.


hte <- posts_sx %>%
  filter(parameter=="p_global" & item_valence=="pos") %>%
  group_by(uid) %>%
  mutate(psychoed = ifelse(uid %in% controls, 0, 1),
         deltaPpos = mean[session==2] - mean[session==1]) %>%
  filter(session==1) %>%
  ungroup() %>%
  mutate(deltaPposStd = deltaPpos / sd(mean)) %>%
  group_by(psychoed) %>%
  summarise(sd = sd(deltaPposStd), N=n())

SD_exp <- hte$sd[hte$psychoed==1]
DF_exp <- hte$N[hte$psychoed==1] - 1
SD_con <- hte$sd[hte$psychoed==0]
DF_con <- hte$N[hte$psychoed==0] - 1
SD_IR <- sqrt(SD_exp^2 - SD_con^2)

print(paste0("Point estimate for SD of individual responses in mean global theta_pos: ",
             round(SD_IR,3)), quotes=FALSE)

# Confidence limits for the standard deviation are obtained by assuming its sampling variance is normally distributed, with standard error given by √[2(SDExp4/DFExp+SDCon4/DFCon)], where DFExp and DFCon are the degrees of freedom of the standard deviations in the two groups (usually their sample sizes minus 1).
SD_IR_se <- sqrt(2 * ( SD_exp^4/DF_exp + SD_con^4/DF_con))

# The upper and lower confidence limits for the true value of the variance of individual responses (SDIR2) are given by its observed value plus or minus this standard error times 1.65, 1.96, or 2.58 for 90, 95, or 99% confidence limits, respectively
print(paste0("95% CI for variance in individual responses in mean global theta_pos: ",
             round(SD_IR - 1.96*SD_IR_se,3), 
             " - ",
             round(SD_IR + 1.96*SD_IR_se,3)), quotes=FALSE)

# The thresholds for interpreting the standardized mean change (0.2, 0.6, 1.2, 2.0, and 4.0 for small, moderate, large, very large, and extremely large) (6) need to be halved (0.1, 0.3, 0.6, 1.0, and 2.0) for interpreting the magnitude of effects represented by standardized standard deviations (8), including individual responses.
```

```{r sx_grm_2}
# # analysis of symptom data to create 'latent' symptom scores, using a form of IRT called a Graded Response Model
# # first, grab the data we want to model
nPpts_sx <- length(unique(data_quest_wide_all$uid))

sx_grm <- data_quest_wide_all %>%
  arrange(uid) %>%
  dplyr::select(PHQ9_2, PHQ9_6, DAS_1, DAS_2, DAS_3, DAS_4, DAS_5, DAS_6, DAS_8, DAS_9, uid) %>% 
  arrange(uid) %>%
  mutate(IDsx = seq(1, nPpts_sx, 1)) %>%
  mutate(across(contains("DAS"),
               ~recode(., `0`=4,`1`=3,`2`=2,`3`=1))) %>% # all items are reverse scored
  melt(id.vars=c("IDsx", "uid")) %>%
  arrange(IDsx, variable) %>%
  mutate(value = as.numeric(value),
         variable2 = unclass(variable))

nItems <- max(sx_grm$variable2)

## create list to pass to stan
data_list <- list(
  nPpts = nPpts_sx,           # number of participants
  nItems = nItems,            # number of items per participant
  N = nrow(sx_grm),           # total number of observations
  jj = sx_grm$IDsx,           # person id for observation n
  ii = sx_grm$variable2,      # item id for observation n
  y = sx_grm$value            # response for observations n; y in {0 ... m_i}
)
```


```{r fit_grm}
## specify full model name and list of parameters to save in output (otherwise big)
model <- "m_grm_2"

## fit model using rstan
fit_grm <- stan(
  file = paste0("./stan-models/", model, ".stan"),
  data = data_list,
  chains = 4,               # run 4 separate chains to assess convergence
  warmup = 1000,            # these are used to tune the sampler and ’burn in’
  iter = 2000,              # number of iterations (#kept = chains*(iter - warmup))
  cores = nCores            # chains to be run in parallel on separate cores (if possible)
)

## save
saveRDS(fit_grm, file = paste0("./stan-fits/", model, "-", task_ver, "-negcog-fit.rds"))
# fit_grm <- readRDS(file = paste0("./stan-fits/", model, "-", task_ver, "-negcog-fit.rds"))

# diagnostics
check_hmc_diagnostics(fit_grm)

# look at posterior marginal param dists
params <- rstan::extract(fit_grm)
hist(params$theta, main="", xlab="relative participant endorsement",
            yaxt='n', ylab="")

hist(params$alpha, main="", xlab="overall item discriminability",
            yaxt='n', ylab="")

hist(params$kappa, main="", xlab="overall item difficulty",
            yaxt='n', ylab="")

# plot contribution of each item to scores
var_dict <- data_quest_wide_all %>%
  dplyr::select(PHQ9_2, PHQ9_6, DAS_1, DAS_2, DAS_3, DAS_4, DAS_5, DAS_6, DAS_8, DAS_9, # negcog items
                uid) %>%
  mutate(ID = seq(1, nPpts, 1)) %>%
  melt(id.vars=c("ID", "uid")) %>%
  arrange(ID, variable) %>%
  mutate(variable2 = unclass(variable)) %>%
  dplyr::select(variable, variable2) %>%
  distinct()

fit_grm_tidy <- fit_grm %>%
  spread_draws(alpha[item]) %>%
  mutate(item = as.factor(item))

pa <- fit_grm_tidy %>%
  mutate(scale = "negative cognition") %>%
  ggplot(aes(x = alpha, y = fct_rev(item), fill = scale)) +
  stat_gradientinterval(.width = c(.9, .5)) +
  geom_vline(xintercept=0, colour="grey") + 
  geom_vline(xintercept=1, colour="grey", linetype="dashed") +
  scale_y_discrete(labels = var_dict$variable[1:11]) + xlim(-1,5) +
  labs(x="posterior item discriminability\n for negative cognition", y="") +
  scale_fill_manual(values = colours2) +
  theme_tidybayes() + theme(legend.position="none") + theme(aspect.ratio=4.5/3)
pa
# ggsave(filename = paste0("./figures/", task_ver, "-", model, "-alpha-negcog-gradient.svg"),
#        plot = last_plot(), device = "svg", dpi = 300)
```

```{r sx_grm_merge}
# get posterior estimates for grm parameter
posts_grm <- as.data.frame(summary(fit_grm, pars = c("theta"))$summary) %>%
  dplyr::select(mean, sd) %>%
  add_rownames(var = "var") %>%
  separate(var, sep="\\[|\\,|\\]", into=c("parameter", "ID"), 
           remove=TRUE, extra="drop")

# merge sx into posts data
posts_grm_uids <- merge(posts_grm, ID_trans, by="ID")
posts_sx_grm <- merge(posts_grm_uids, data_quest_wide_all, by = "uid")

# plot relationships between grm posterior means and sx scores
p1 <- posts_sx_grm %>%
  ggplot(aes(x = DAS_total, y = mean)) +
  geom_point() +
  geom_smooth(method = "lm", se=TRUE, alpha=.2, color="black", formula = y ~ x) +
  stat_poly_eq(formula = y~x, label.x = "right", label.y = "top",
               aes(label = paste(stat(rr.label), stat(p.value.label), sep = "~~~")),
               parse = TRUE) +
  theme_minimal()

p2 <- posts_sx_grm %>%
  ggplot(aes(x = PHQ9_total, y = mean)) +
  geom_point() +
  geom_smooth(method = "lm", se=TRUE, alpha=.2, color="black", formula = y ~ x) +
  stat_poly_eq(formula = y~x, label.x = "right", label.y = "top",
               aes(label = paste(stat(rr.label), stat(p.value.label), sep = "~~~")),
               parse = TRUE) +
  theme_minimal()

p3 <- posts_sx_grm %>%
  ggplot(aes(x = miniSPIN_total, y = mean)) +
  geom_point() +
  geom_smooth(method = "lm", se=TRUE, alpha=.2, color="black", formula = y ~ x) +
  stat_poly_eq(formula = y~x, label.x = "right", label.y = "top",
               aes(label = paste(stat(rr.label), stat(p.value.label), sep = "~~~")),
               parse = TRUE) +
  theme_minimal()

( p1 + p2 + p3)
```

```{r pre_data_joint}
# check we have behaviour and sx data from the same subjects
grep(FALSE, unique(data_quest_wide_all$uid)==unique(data_long_all$uid))

## create arrays of choice options and responses for each participant and time point
internalChosen_neg <- internalChosen_pos <- globalChosen_neg <- globalChosen_pos <- array(0, dim = c(nPpts, nTimes, nTrials_max/2))
nT_ppts <- array(nTrials_max, dim = c(nPpts, nTimes))
for (i in 1:nPpts) {
  for (t in 1:nTimes) {
    internalChosen_neg[i,t,] <- with(data_long_all, internalChosen[ID==i & sess==t & neg_pos==0])
    internalChosen_pos[i,t,] <- with(data_long_all, internalChosen[ID==i & sess==t & neg_pos==1])
    globalChosen_neg[i,t,] <- with(data_long_all, globalChosen[ID==i & sess==t & neg_pos==0])
    globalChosen_pos[i,t,] <- with(data_long_all, globalChosen[ID==i & sess==t & neg_pos==1])
  }
}

## create list to pass to stan
data_list = list(
  nTimes = nTimes,
  nPpts = nPpts_sx,
  nTrials_max = nTrials_max/2,         # max number of trials per  session per participant
  nT_ppts = nT_ppts,                   # actual number of trials per session per participant
  condition = int_conds$condition01,   # 0 = control, 1 = psychoed
  internal_neg = internalChosen_neg,
  internal_pos = internalChosen_pos,
  global_neg = globalChosen_neg,
  global_pos = globalChosen_pos,
  nItems = nItems,                     # number of items per participant
  N = nrow(sx_grm),                    # total number of observations
  jj = sx_grm$IDsx,                    # person id for observation n
  ii = sx_grm$variable2,               # item id for observation n
  y = sx_grm$value                     # response for observations n; y in {0 ... m_i}
)
```


```{r fit_joint_baseline}
model <- "m_bernoulli_negpos_IGcorr2_multisess_intervention_additive_joint_base2"

## fit model using rstan
fit <- stan(
  file = paste0("./stan-models/", model, ".stan"),
  data = data_list,
  chains = 4,               # run 4 separate chains to assess convergence
  warmup = 1000,            # these are used to tune the sampler and ’burn in’
  iter = 2000,              # number of iterations (#kept = chains*(iter - warmup))
  cores = nCores            # chains to be run in parallel on separate cores (if possible)
)

## save
saveRDS(fit, file = paste0("./stan-fits/", model, "-", task_ver, "-fit.rds"))
#fit <- readRDS(file = paste0("./stan-fits/", model ,"-", task_ver, "-fit.rds"))

# summary of sampling diagnostics
check_hmc_diagnostics(fit)

# plot pairs of sampling distributions for an example participant
pairs(fit, pars=c("theta_internal_neg[1,1]", "theta_internal_neg[2,1]",
                  "theta_global_neg[1,1]",   "theta_global_neg[2,1]"))
pairs(fit, pars=c("theta_internal_pos[1,1]", "theta_internal_pos[2,1]",
                  "theta_global_pos[1,1]",   "theta_global_pos[2,1]"))

# plot pairs of sampling distributions for the group level means
pairs(fit, pars=c("mu_internal_theta_neg[1]", "mu_internal_theta_neg[2]",
                  "mu_global_theta_neg[1]",   "mu_global_theta_neg[2]"))
pairs(fit, pars=c("mu_internal_theta_pos[1]", "mu_internal_theta_pos[2]",
                  "mu_global_theta_pos[1]",   "mu_global_theta_pos[2]"))

# plot intervention and individual t2 a[irs ]
pairs(fit, pars=c("theta_int_internal_neg", "theta_int_global_neg"))
pairs(fit, pars=c("theta_int_internal_pos", "theta_int_global_pos", "beta_int"))

# plot using tidybayes package (quick and pretty!)
fit_tidy <- fit %>% 
  gather_draws(theta_int_internal_neg, theta_int_internal_pos,
               theta_int_global_neg, theta_int_global_pos,
               b1, 
               beta_int) %>%
  mutate(var_type = ifelse(grepl("theta_int", .variable), "intervention effect", 
                           ifelse(grepl("beta_int", .variable), "negative cognition",
                                  "negative cognition")),
         var_type = factor(var_type, levels = c("group mean", "intervention effect", 
                                                "amotivation", "negative cognition")),
         .variable = factor(.variable, levels = c(
           "theta_int_internal_neg", "theta_int_internal_pos",
           "theta_int_global_neg", "theta_int_global_pos",
           "b1", 
           "beta_int")))

p <- fit_tidy %>%
  ggplot(aes(y = fct_rev(.variable), x = .value, fill = var_type)) +
  stat_gradientinterval(.width = c(.9, .5),  slab_size = 1) +
  scale_fill_manual(values = colours2) +
  geom_vline(xintercept = 0, colour = "grey") + theme_minimal() + xlim(-1.2,1.2) +
  theme(legend.position = "none") + theme(aspect.ratio=2/7) + labs(x="", y="") +
  theme(text = element_text(size = 20))
p
ggsave(filename = paste0("./figures/", task_ver, "-", model,
                         "means-ints-joint-CIs-baseline-gradient.svg"),
       plot = last_plot(), device = "svg", dpi = 300)

# print numerical values for CIs
params90cis <- summary(fit, pars = c("theta_int_internal_neg", "theta_int_internal_pos",
                        "theta_int_global_neg", "theta_int_global_pos", "b1",
                        "beta_int"
                        ), probs = c(0.1, 0.9))$summary
print(params90cis)

## new plotting
## convert to ~standardized betas
# beta_b1_std =  sqrt(sigma_thetas[1]) / sqrt(pars_sigma_pos[1]) * beta_b1
# beta_int1_std = sqrt(sigma_thetas[1]) / sqrt(pars_sigma_pos[3]) * beta_int1
# first, get posterior (pooled) variance estimates for theta_internal_pos at each time point
params90cis <- summary(fit, pars = c("pars_sigma_pos[1]",
                                     "pars_sigma_pos[3]"), 
                       probs = c(0.1, 0.9))$summary
sigma_theta_int_pos_t1 <- params90cis[1,1]
sigma_theta_int_pos_t2 <- params90cis[2,1]
# for thetas, which are non hierarchically estimates, we will have to take the SD across posterior mean estimates
tmp  <- summary(fit, pars = "theta", probs = c(0.1, 0.9))$summary
sd_thetaN <- sd(tmp[,1])

fit_tidy2 <- fit_tidy %>%
  mutate(.value2 = case_when(.variable =="b1" ~ sd_thetaN/sqrt(sigma_theta_int_pos_t1) *.value,
                             .variable =="beta_int" ~ sd_thetaN/sqrt(sigma_theta_int_pos_t2) *.value,
                             TRUE ~ .value))
p2 <- fit_tidy2 %>%
  ggplot(aes(y = fct_rev(.variable), x = .value2, fill = var_type)) +
  stat_gradientinterval(.width = c(.9, .5),  slab_size = 1) +
  scale_fill_manual(values = colours2) +
  geom_vline(xintercept = 0, colour = "grey") + theme_minimal() + xlim(-1,1) +
  theme(legend.position = "none") + theme(aspect.ratio=2/7) + labs(x="", y="") +
  theme(text = element_text(size = 20))
p2
# ggsave(filename = paste0("./figures/", task_ver, "-", model,
#                          "-joint-CIs-baseline-gradient-transf.svg"),
#        plot = last_plot(), device = "svg", dpi = 300)
```
